{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c831bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import torch.utils.data\n",
    "#from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import zookeeper as zk  # convool_size & mappy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa971be",
   "metadata": {},
   "source": [
    "import shutil\n",
    "    \n",
    "data = pd.read_csv('../data/og/training_solutions_rev1.csv')\n",
    "test = data.sample(frac=.1)\n",
    "train = data.drop(test.index)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "train.to_csv('../data/training/training_solutions_rev1.csv', index_label=False)\n",
    "test.to_csv('../data/test/test_solutions_rev1.csv', index_label=False)\n",
    "\n",
    "for image in (train.GalaxyID.astype('string') + '.jpg').values:\n",
    "    shutil.move(os.path.join('../data/og/', image), os.path.join('../data/training/', image))\n",
    "\n",
    "for image in (test.GalaxyID.astype('string') + '.jpg').values:\n",
    "    shutil.move(os.path.join('../data/og/', image), os.path.join('../data/test/', image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c70a1",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c175bb",
   "metadata": {},
   "source": [
    "\n",
    "pd.read_csv('../data/test/test_solutions_rev1.csv').shape[0] + pd.read_csv('../data/training/training_solutions_rev1.csv').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f15060",
   "metadata": {},
   "source": [
    "### Define Dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cac3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyJungle(Dataset):\n",
    "    \n",
    "    #the init function initializes the directory containing the image,\n",
    "    #the annotations file,\n",
    "    #and both transforms\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, is_rgb=False):\n",
    "        self.rgb = is_rgb\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    #returns number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return (self.img_labels).shape[0]\n",
    "\n",
    "    #loads a sample from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])) + '.jpg'\n",
    "        #retrieves the image\n",
    "        image = Image.open(img_path)\n",
    "        if not self.rgb: image = image.convert('L')\n",
    "        #retrieves corresponding label\n",
    "        label = self.img_labels.iloc[idx, 1:]\n",
    "        #if possible, transform the image and the label into a tensor.\n",
    "        if self.transform:\n",
    "            image = self.transform(image).type(torch.float16)\n",
    "        label = torch.tensor(label.values, dtype=torch.float16)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, self.img_labels.iloc[idx, 0]\n",
    "    \n",
    "\n",
    "transfs = transforms.Compose([\n",
    "    transforms.ToTensor(), # Riscala le immagini tra 0 e 1\n",
    "    transforms.CenterCrop(324),\n",
    "    transforms.Resize(128),\n",
    "    transforms.RandomRotation(180)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0592f53",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d162ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyNet(nn.Module):\n",
    "    def __init__(self, activation, initialization=False, is_rgb=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        rgb = 3 if is_rgb else 1\n",
    "        input_size = 128\n",
    "        num_labels = 37\n",
    "        \n",
    "        self.loss_dict = {'batch' : [], 'epoch' : [], 'vbatch' : [], 'vepoch' : []}\n",
    "        self.activation = activation\n",
    "\n",
    "        \n",
    "        ## convolutional layers\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(rgb, 32, 3),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.Conv2d(32, 32, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 64, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(64),            \n",
    "\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "        for layer in self.convs:\n",
    "            if layer.__class__.__name__ == 'Conv2d': input_size = zk.convool_size(input_size, 3, 1)\n",
    "            elif layer.__class__.__name__ == 'MaxPool2d': input_size = zk.convool_size(input_size, 2, 2)\n",
    "\n",
    "        if input_size < 2: raise ValueError('You shrank too much dude.')\n",
    "\n",
    "        input_linear = 128 * input_size * input_size\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_linear, 100),\n",
    "            self.activation(),\n",
    "            nn.Linear(100, num_labels)\n",
    "            )\n",
    "        \n",
    "        if initialization: self.init_weights()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        if self.activation == nn.ReLU:\n",
    "            nonlin = 'relu'\n",
    "            a = 0\n",
    "        elif self.activation == nn.LeakyReLU:\n",
    "            nonlin = 'leaky_relu'\n",
    "            a = .01\n",
    "        \n",
    "        # Init convolutional parameters\n",
    "        for layer in self.convs: \n",
    "            if layer.__class__.__name__ == 'Conv2d': nn.init.kaiming_normal_(layer.weight, a=a, nonlinearity=nonlin)\n",
    "        \n",
    "\n",
    "        # Init lienar parameters\n",
    "        for i in (1, -1): nn.init.constant_(self.fc[i].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc[1].weight, a=a, nonlinearity=nonlin)\n",
    "        nn.init.xavier_uniform_(self.fc[-1].weight)      \n",
    "        \n",
    "\n",
    "\n",
    "    def log_the_loss(self, item,epoch=False): # per avere una history della loss???\n",
    "        verbose=False\n",
    "        train = self.__getstate__()['training']\n",
    "        if verbose: print(train)\n",
    "        if epoch and train:\n",
    "            self.loss_dict['epoch'].append(item) ### get state of the model so you can ditch the validation parameter\n",
    "        elif not epoch and train:\n",
    "            self.loss_dict['batch'].append(item)\n",
    "        elif not train and epoch:\n",
    "            self.loss_dict['vepoch'].append(item)\n",
    "        elif not train and not epoch:\n",
    "            self.loss_dict['vbatch'].append(item)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357637a",
   "metadata": {},
   "source": [
    "## TRAINING + VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8aedbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(model, train_loader, optimizer, loss_function, verbose=False):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        inputs,labels, _ = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs) #, activation=F.relu)\n",
    "        loss=loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # fa update del parameter\n",
    "        RMSEloss = np.sqrt(loss.item())\n",
    "        running_loss += RMSEloss\n",
    "        if verbose and i%10 ==0: print(f'Batch {i+1}/{len(train_loader)} - Loss: {RMSEloss:.3f}')\n",
    "\n",
    "        model.log_the_loss(RMSEloss, epoch=False)\n",
    "    epochmean_loss = running_loss / len(train_loader)\n",
    "    print(f'\\nLoss: {epochmean_loss}')\n",
    "    model.log_the_loss(epochmean_loss, epoch=True)\n",
    "    last_loss = RMSEloss\n",
    "    print(f\"Last loss: {last_loss}\")\n",
    "    return epochmean_loss\n",
    "\n",
    "\n",
    "\n",
    "def one_epoch_eval(model, test_loader, loss_function, verbose=False):\n",
    "    model.eval()\n",
    "    running_validation_loss = 0.\n",
    "   \n",
    "    with torch.no_grad(): # deactivates gradient evaluation\n",
    "        for i, vdata in tqdm(enumerate(test_loader)):\n",
    "            inputs,labels, _ = vdata\n",
    "            inputs,labels= inputs.to(device), labels.to(device)\n",
    "            with torch.autocast('cuda'):\n",
    "                outputs = model(inputs)#, activation=F.relu)\n",
    "                loss = loss_function(outputs ,labels)\n",
    "            RMSEloss = np.sqrt(loss.item())\n",
    "            running_validation_loss +=RMSEloss\n",
    "            model.log_the_loss(RMSEloss,epoch=False)\n",
    "    mean_vloss=model.log_the_loss(running_validation_loss/len(test_loader),epoch=True)\n",
    "    print(f\"Validation Loss: {mean_vloss}\\n---\")\n",
    "    return mean_vloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590107b",
   "metadata": {},
   "source": [
    "## OPTUNA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3343a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = GalaxyJungle('../data/training/training_solutions_rev1.csv', '../data/training/', transfs)\n",
    "training, test = random_split(DS, [.8, .2])\n",
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "    activation = trial.suggest_categorical(\"activation\", ['ReLU', 'LeakyReLU'])\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'AdamW', 'RMSprop', 'Adagrad', 'NAdam']) #AdamW Ã¨ suggerito per CNN.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True) #log true cerca i valori in scala logaritmica\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.5, 0.9, step=0.1) #per SGD\n",
    "    initialization = trial.suggest_categorical('init weight', [True, False])\n",
    "    epochs = 50\n",
    "    loss_function = nn.MSELoss()\n",
    "    train_loader = DataLoader(training, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "    test_loader = DataLoader(test, batch_size=32, shuffle=False, num_workers=os.cpu_count())    \n",
    "\n",
    "    ##### Training phase\n",
    "    activation = getattr(nn, activation)\n",
    "    model = GalaxyNet(activation, initialization).half().to(device)\n",
    "    if optimizer in ('SGD', \"RMSprop\"): optimizer = getattr(optim, optimizer)(model.parameters(), lr=learning_rate, momentum = momentum)\n",
    "    else: optimizer = getattr(optim, optimizer)(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Training epoch {epoch}')\n",
    "        train_loss = one_epoch_train(model, train_loader, optimizer, loss_function, verbose=True)\n",
    "        trial.report(train_loss, epoch)\n",
    "\n",
    "        print(f'Validation epoch {epoch}')\n",
    "        epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
    "        trial.report(epoch_last_val_loss, epoch)\n",
    "\n",
    "        if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "    \n",
    "    score = epoch_last_val_loss\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9b544c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-22 09:23:22,352] Using an existing study with name 'JAGZooNet' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Using an existing study with name 'JAGZooNet' instead of creating a new one.\n",
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/1386 - Loss: 1.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 22.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11/1386 - Loss: 0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 26.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21/1386 - Loss: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:01, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 31/1386 - Loss: 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:02, 24.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 41/1386 - Loss: 0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:02, 27.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 51/1386 - Loss: 0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:02, 27.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 61/1386 - Loss: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:03, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71/1386 - Loss: 0.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:03, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 81/1386 - Loss: 0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:04, 30.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 91/1386 - Loss: 0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [00:04, 25.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 101/1386 - Loss: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [00:04, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 111/1386 - Loss: 0.270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 22.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 121/1386 - Loss: 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134it [00:05, 24.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 131/1386 - Loss: 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "142it [00:06, 25.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 141/1386 - Loss: 0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:06, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 151/1386 - Loss: 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:06, 27.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 161/1386 - Loss: 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174it [00:07, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 171/1386 - Loss: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:07, 27.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 181/1386 - Loss: 0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [00:07, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 191/1386 - Loss: 0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:08, 26.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 201/1386 - Loss: 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [00:08, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 211/1386 - Loss: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:09, 24.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 221/1386 - Loss: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:09, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 231/1386 - Loss: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "247it [00:10, 26.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 241/1386 - Loss: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "254it [00:10, 26.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 251/1386 - Loss: 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [00:10, 24.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 261/1386 - Loss: 0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [00:11, 26.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 271/1386 - Loss: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [00:11, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 281/1386 - Loss: 0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [00:12, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 291/1386 - Loss: 0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "305it [00:12, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 301/1386 - Loss: 0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [00:13, 23.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 311/1386 - Loss: 0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "326it [00:13, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 321/1386 - Loss: 0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "333it [00:13, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 331/1386 - Loss: 0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343it [00:14, 20.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 341/1386 - Loss: 0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "356it [00:14, 26.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 351/1386 - Loss: 0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "365it [00:15, 22.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 361/1386 - Loss: 0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "376it [00:15, 27.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 371/1386 - Loss: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [00:15, 25.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 381/1386 - Loss: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "393it [00:16, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 391/1386 - Loss: 0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "407it [00:17, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 401/1386 - Loss: 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "414it [00:17, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 411/1386 - Loss: 0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "425it [00:17, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 421/1386 - Loss: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "434it [00:18, 23.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 431/1386 - Loss: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "443it [00:18, 23.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 441/1386 - Loss: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "453it [00:18, 24.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 451/1386 - Loss: 0.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "462it [00:19, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 461/1386 - Loss: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "475it [00:19, 25.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 471/1386 - Loss: 0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "485it [00:20, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 481/1386 - Loss: 0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [00:20, 26.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 491/1386 - Loss: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:21, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 501/1386 - Loss: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "514it [00:21, 24.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 511/1386 - Loss: 0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "522it [00:21, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 521/1386 - Loss: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "533it [00:22, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 531/1386 - Loss: 0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "543it [00:22, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 541/1386 - Loss: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "553it [00:23, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 551/1386 - Loss: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "564it [00:23, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 561/1386 - Loss: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "572it [00:24, 27.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 571/1386 - Loss: 0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "584it [00:24, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 581/1386 - Loss: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "592it [00:25, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 591/1386 - Loss: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "607it [00:25, 23.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 601/1386 - Loss: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "614it [00:25, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 611/1386 - Loss: 0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "621it [00:26, 24.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 621/1386 - Loss: 0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "634it [00:26, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 631/1386 - Loss: 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "646it [00:27, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 641/1386 - Loss: 0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "653it [00:27, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 651/1386 - Loss: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "663it [00:28, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 661/1386 - Loss: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "673it [00:28, 19.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 671/1386 - Loss: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "684it [00:29, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 681/1386 - Loss: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "692it [00:29, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 691/1386 - Loss: 0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "703it [00:29, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 701/1386 - Loss: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "713it [00:30, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 711/1386 - Loss: 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "724it [00:30, 23.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 721/1386 - Loss: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "732it [00:31, 21.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 731/1386 - Loss: 0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "743it [00:31, 22.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 741/1386 - Loss: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "753it [00:32, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 751/1386 - Loss: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "764it [00:32, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 761/1386 - Loss: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "774it [00:33, 27.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 771/1386 - Loss: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "784it [00:33, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 781/1386 - Loss: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "794it [00:34, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 791/1386 - Loss: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "805it [00:34, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 801/1386 - Loss: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "815it [00:34, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 811/1386 - Loss: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "822it [00:35, 26.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 821/1386 - Loss: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "833it [00:35, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 831/1386 - Loss: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "843it [00:36, 22.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 841/1386 - Loss: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "854it [00:36, 23.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 851/1386 - Loss: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "864it [00:36, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 861/1386 - Loss: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "873it [00:37, 22.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 871/1386 - Loss: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "887it [00:37, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 881/1386 - Loss: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "893it [00:38, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 891/1386 - Loss: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "904it [00:38, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 901/1386 - Loss: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "914it [00:39, 23.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 911/1386 - Loss: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:39, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 921/1386 - Loss: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "936it [00:40, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 931/1386 - Loss: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "943it [00:40, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 941/1386 - Loss: 0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "954it [00:40, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 951/1386 - Loss: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "966it [00:41, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 961/1386 - Loss: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "975it [00:41, 23.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 971/1386 - Loss: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [00:42, 23.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 981/1386 - Loss: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "995it [00:42, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 991/1386 - Loss: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:42, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1001/1386 - Loss: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1015it [00:43, 23.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1011/1386 - Loss: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1026it [00:43, 23.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1021/1386 - Loss: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1035it [00:44, 23.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1031/1386 - Loss: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1042it [00:44, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1041/1386 - Loss: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1052it [00:45, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1051/1386 - Loss: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1065it [00:45, 23.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1061/1386 - Loss: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1076it [00:46, 24.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1071/1386 - Loss: 0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1084it [00:46, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1081/1386 - Loss: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1093it [00:46, 23.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1091/1386 - Loss: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1106it [00:47, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1101/1386 - Loss: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1113it [00:47, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1111/1386 - Loss: 0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [00:48, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1121/1386 - Loss: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1133it [00:48, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1131/1386 - Loss: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1143it [00:49, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1141/1386 - Loss: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1156it [00:49, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1151/1386 - Loss: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1166it [00:50, 20.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1161/1386 - Loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1173it [00:50, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1171/1386 - Loss: 0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1183it [00:51, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1181/1386 - Loss: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1195it [00:51, 22.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1191/1386 - Loss: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [00:51, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1201/1386 - Loss: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1211it [00:52, 24.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1211/1386 - Loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1225it [00:52, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1221/1386 - Loss: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1235it [00:53, 25.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1231/1386 - Loss: 0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1245it [00:53, 23.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1241/1386 - Loss: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1255it [00:54, 23.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1251/1386 - Loss: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1265it [00:54, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1261/1386 - Loss: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1276it [00:54, 26.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1271/1386 - Loss: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1286it [00:55, 26.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1281/1386 - Loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1295it [00:55, 23.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1291/1386 - Loss: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1302it [00:56, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1301/1386 - Loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1314it [00:56, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1311/1386 - Loss: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1324it [00:57, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1321/1386 - Loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1334it [00:57, 22.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1331/1386 - Loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1344it [00:58, 21.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1341/1386 - Loss: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1351it [00:58, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1351/1386 - Loss: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1364it [00:59, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1361/1386 - Loss: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1374it [00:59, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1371/1386 - Loss: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1386it [00:59, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1381/1386 - Loss: 0.204\n",
      "\n",
      "Loss: 0.23119398707353325\n",
      "Last loss: 0.22575286369999828\n",
      "Validation epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "276it [00:11, 23.34it/s]\n",
      "[W 2025-05-22 09:24:34,806] Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 6 failed with parameters: {'activation': 'ReLU', 'optimizer': 'SGD', 'learning_rate': 0.004560018160550374, 'momentum': 0.5, 'init weight': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/1712323605.py\", line 28, in objective\n",
      "    epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23899/581798852.py\", line 31, in one_epoch_eval\n",
      "    for i, vdata in tqdm(enumerate(test_loader)):\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-22 09:24:34,827] Trial 6 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 failed with value None.\n",
      "Trial 6 failed with value None.\n",
      "Trial 6 failed with value None.\n",
      "Trial 6 failed with value None.\n",
      "Trial 6 failed with value None.\n",
      "Trial 6 failed with value None.\n",
      "Trial 6 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m storage_name = \u001b[33m\"\u001b[39m\u001b[33msqlite:///\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.db\u001b[39m\u001b[33m\"\u001b[39m.format(study_name)\n\u001b[32m      4\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m, study_name=study_name, storage=storage_name, load_if_exists=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m study.optimize(objective, n_trials=\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     _optimize(\n\u001b[32m    476\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    477\u001b[39m         func=func,\n\u001b[32m    478\u001b[39m         n_trials=n_trials,\n\u001b[32m    479\u001b[39m         timeout=timeout,\n\u001b[32m    480\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    481\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    482\u001b[39m         callbacks=callbacks,\n\u001b[32m    483\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    484\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    485\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         _optimize_sequential(\n\u001b[32m     64\u001b[39m             study,\n\u001b[32m     65\u001b[39m             func,\n\u001b[32m     66\u001b[39m             n_trials,\n\u001b[32m     67\u001b[39m             timeout,\n\u001b[32m     68\u001b[39m             catch,\n\u001b[32m     69\u001b[39m             callbacks,\n\u001b[32m     70\u001b[39m             gc_after_trial,\n\u001b[32m     71\u001b[39m             reseed_sampler_rng=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     72\u001b[39m             time_start=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     73\u001b[39m             progress_bar=progress_bar,\n\u001b[32m     74\u001b[39m         )\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = _run_trial(study, func, catch)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = func(trial)\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     25\u001b[39m trial.report(train_loss, epoch)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mValidation epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     29\u001b[39m trial.report(epoch_last_val_loss, epoch)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trial.should_prune(): \u001b[38;5;28;01mraise\u001b[39;00m optuna.TrialPruned()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mone_epoch_eval\u001b[39m\u001b[34m(model, test_loader, loss_function, verbose)\u001b[39m\n\u001b[32m     28\u001b[39m running_validation_loss = \u001b[32m0.\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(): \u001b[38;5;66;03m# deactivates gradient evaluation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, vdata \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(test_loader)):\n\u001b[32m     32\u001b[39m         inputs,labels, _ = vdata\n\u001b[32m     33\u001b[39m         inputs,labels= inputs.to(device), labels.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m   1182\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[32m   1183\u001b[39m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1448\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m idx, data = \u001b[38;5;28mself\u001b[39m._get_data()\n\u001b[32m   1449\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1412\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1409\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m         success, data = \u001b[38;5;28mself\u001b[39m._try_get_data()\n\u001b[32m   1413\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1414\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1243\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1231\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1241\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m         data = \u001b[38;5;28mself\u001b[39m._data_queue.get(timeout=timeout)\n\u001b[32m   1244\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1247\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = wait([\u001b[38;5;28mself\u001b[39m], timeout)\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = selector.select(timeout)\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28mself\u001b[39m._selector.poll(timeout)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"JAGZooNet\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jungle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
