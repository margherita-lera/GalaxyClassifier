{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c831bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import torch.utils.data\n",
    "#from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import zookeeper as zk  # convool_size & mappy\n",
    "import pickle  # for artifact, maybe not useful\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa971be",
   "metadata": {},
   "source": [
    "import shutil\n",
    "    \n",
    "data = pd.read_csv('../data/og/training_solutions_rev1.csv')\n",
    "test = data.sample(frac=.1)\n",
    "train = data.drop(test.index)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "train.to_csv('../data/training/training_solutions_rev1.csv', index_label=False)\n",
    "test.to_csv('../data/test/test_solutions_rev1.csv', index_label=False)\n",
    "\n",
    "for image in (train.GalaxyID.astype('string') + '.jpg').values:\n",
    "    shutil.move(os.path.join('../data/og/', image), os.path.join('../data/training/', image))\n",
    "\n",
    "for image in (test.GalaxyID.astype('string') + '.jpg').values:\n",
    "    shutil.move(os.path.join('../data/og/', image), os.path.join('../data/test/', image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c70a1",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c175bb",
   "metadata": {},
   "source": [
    "\n",
    "pd.read_csv('../data/test/test_solutions_rev1.csv').shape[0] + pd.read_csv('../data/training/training_solutions_rev1.csv').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f15060",
   "metadata": {},
   "source": [
    "### Define Dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cac3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyJungle(Dataset):\n",
    "    \n",
    "    #the init function initializes the directory containing the image,\n",
    "    #the annotations file,\n",
    "    #and both transforms\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, is_rgb=False):\n",
    "        self.rgb = is_rgb\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    #returns number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return (self.img_labels).shape[0]\n",
    "\n",
    "    #loads a sample from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])) + '.jpg'\n",
    "        #retrieves the image\n",
    "        image = Image.open(img_path)\n",
    "        if not self.rgb: image = image.convert('L')\n",
    "        #retrieves corresponding label\n",
    "        label = self.img_labels.iloc[idx, 1:]\n",
    "        #if possible, transform the image and the label into a tensor.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)#.type(torch.float16)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, self.img_labels.iloc[idx, 0]\n",
    "    \n",
    "\n",
    "transfs = transforms.Compose([\n",
    "    transforms.ToTensor(), # Riscala le immagini tra 0 e 1\n",
    "    transforms.CenterCrop(324),\n",
    "    transforms.Resize(128),\n",
    "    transforms.RandomRotation(180)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0592f53",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d00368",
   "metadata": {},
   "source": [
    "al = [0, 0, 2, 0, 0, 2, 1, 2, 1, 2, 1, 2]\n",
    "inp = 128\n",
    "for i in al:\n",
    "    if i == 0: inp = zk.convool_size(inp, 3, 1, 'same')\n",
    "    elif i == 2: inp = zk.convool_size(inp, 2, 2)\n",
    "    else: inp = zk.convool_size(inp, 3, 1)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d162ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyNet(nn.Module):\n",
    "    def __init__(self, activation, initialization=False, is_rgb=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        rgb = 3 if is_rgb else 1\n",
    "        input_size = 128\n",
    "        num_labels = 37\n",
    "        \n",
    "        self.loss_dict = {'batch' : [], 'epoch' : [], 'vbatch' : [], 'vepoch' : []}\n",
    "        self.activation = activation\n",
    "\n",
    "        \n",
    "        ## convolutional layers\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(rgb, 16, 3, padding='same', bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(16),\n",
    "\n",
    "            nn.Conv2d(16, 16, 3, padding='same', bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(16),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, padding='same', bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "\n",
    "            nn.Conv2d(32, 32, 3, padding='same', bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(64),\n",
    " \n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, bias=False),\n",
    "            self.activation(),\n",
    "            nn.BatchNorm2d(256),            \n",
    "\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "        for layer in self.convs:\n",
    "            if layer.__class__.__name__ == 'Conv2d': input_size = zk.convool_size(input_size, 3, 1, 'same' if layer.padding == 'same' else 0)\n",
    "            elif layer.__class__.__name__ == 'MaxPool2d': input_size = zk.convool_size(input_size, 2, 2)\n",
    "\n",
    "        if input_size < 2: raise ValueError('You shrank too much dude.')\n",
    "        print(f'Convs output size: {input_size}')\n",
    "\n",
    "        input_linear = 256 * input_size * input_size\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_linear, 100),\n",
    "            self.activation(),\n",
    "            nn.Linear(100, num_labels)\n",
    "            )\n",
    "        \n",
    "        if initialization: self.init_weights()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        if self.activation == nn.ReLU:\n",
    "            nonlin = 'relu'\n",
    "            a = 0\n",
    "        elif self.activation == nn.LeakyReLU:\n",
    "            nonlin = 'leaky_relu'\n",
    "            a = .01\n",
    "        \n",
    "        # Init convolutional parameters\n",
    "        for layer in self.convs: \n",
    "            if layer.__class__.__name__ == 'Conv2d': nn.init.kaiming_normal_(layer.weight, a=a, nonlinearity=nonlin)\n",
    "        \n",
    "\n",
    "        # Init linear parameters\n",
    "        for i in (1, -1): nn.init.constant_(self.fc[i].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc[1].weight, a=a, nonlinearity=nonlin)\n",
    "        nn.init.xavier_uniform_(self.fc[-1].weight)      \n",
    "        \n",
    "\n",
    "\n",
    "    def log_the_loss(self, item,epoch=False): # per avere una history della loss???\n",
    "        verbose=False\n",
    "        train = self.__getstate__()['training']\n",
    "        if verbose: print(train)\n",
    "        if epoch and train:\n",
    "            self.loss_dict['epoch'].append(item) ### get state of the model so you can ditch the validation parameter\n",
    "        elif not epoch and train:\n",
    "            self.loss_dict['batch'].append(item)\n",
    "        elif not train and epoch:\n",
    "            self.loss_dict['vepoch'].append(item)\n",
    "        elif not train and not epoch:\n",
    "            self.loss_dict['vbatch'].append(item)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357637a",
   "metadata": {},
   "source": [
    "## TRAINING + VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8aedbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(model, train_loader, optimizer, loss_function, verbose=False):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        inputs,labels, _ = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss=loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # fa update del parameter\n",
    "        RMSEloss = np.sqrt(loss.item())\n",
    "        running_loss += RMSEloss\n",
    "        if verbose and i%10 ==0: print(f'Batch {i+1}/{len(train_loader)} - Loss: {RMSEloss:.3f}')\n",
    "\n",
    "        model.log_the_loss(RMSEloss, epoch=False)\n",
    "    epochmean_loss = running_loss / len(train_loader)\n",
    "    print(f'\\nLoss: {epochmean_loss}')\n",
    "    model.log_the_loss(epochmean_loss, epoch=True)\n",
    "    last_loss = RMSEloss\n",
    "    print(f\"Last loss: {last_loss}\")\n",
    "    return epochmean_loss\n",
    "\n",
    "\n",
    "\n",
    "def one_epoch_eval(model, test_loader, loss_function, verbose=False):\n",
    "    model.eval()\n",
    "    running_validation_loss = 0.\n",
    "   \n",
    "    with torch.no_grad(): # deactivates gradient evaluation\n",
    "        for i, vdata in tqdm(enumerate(test_loader)):\n",
    "            inputs,labels, _ = vdata\n",
    "            inputs,labels= inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)#, activation=F.relu)\n",
    "            loss = loss_function(outputs ,labels)\n",
    "            RMSEloss = np.sqrt(loss.item())\n",
    "            running_validation_loss +=RMSEloss\n",
    "            model.log_the_loss(RMSEloss,epoch=False)\n",
    "    mean_vloss=model.log_the_loss(running_validation_loss / len(test_loader),epoch=True)\n",
    "    print(f\"Validation Loss: {mean_vloss}\\n---\")\n",
    "    return mean_vloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590107b",
   "metadata": {},
   "source": [
    "## OPTUNA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3343a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = GalaxyJungle('../data/training/training_solutions_rev1.csv', '../data/training/', transfs)\n",
    "training, test = random_split(DS, [.8, .2])\n",
    "\n",
    "artifact_store = optuna.artifacts.FileSystemArtifactStore(base_path='./artifacts')\n",
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "    epochs = 50\n",
    "    loss_function = nn.MSELoss()\n",
    "    train_loader = DataLoader(training, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "    test_loader = DataLoader(test, batch_size=32, shuffle=False, num_workers=os.cpu_count())    \n",
    "    \n",
    "    # Trial choices\n",
    "    activation = trial.suggest_categorical(\"activation\", ['ReLU', 'LeakyReLU'])\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'AdamW', 'RMSprop', 'Adagrad', 'NAdam']) #AdamW è suggerito per CNN.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True) #log true cerca i valori in scala logaritmica\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.3, 0.9, step=0.1) #per SGD\n",
    "    initialization = trial.suggest_categorical('init weight', [True, False])\n",
    "    \n",
    "    # Training phase\n",
    "    activation = getattr(nn, activation)\n",
    "    model = GalaxyNet(activation, initialization).to(device)\n",
    "    if optimizer in ('SGD', \"RMSprop\"): optimizer = getattr(optim, optimizer)(model.parameters(), lr=learning_rate, momentum = momentum)\n",
    "    else: optimizer = getattr(optim, optimizer)(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Training epoch {epoch}')\n",
    "        one_epoch_train(model, train_loader, optimizer, loss_function, verbose=False)\n",
    "\n",
    "        print(f'Validation epoch {epoch}')\n",
    "        epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=False)\n",
    "        trial.report(epoch_last_val_loss, epoch)\n",
    "\n",
    "\n",
    "        if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "    with open('model.pickle', 'wb') as fout: pickle.dump(model, fout)\n",
    "    art_id = optuna.artifacts.upload_artifact(artifact_store=artifact_store, file_path='model.pickle', study_or_trial=trial.study)\n",
    "    trial.set_user_attr('artifact_id', art_id)\n",
    "\n",
    "    \n",
    "    return epoch_last_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9b544c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-25 23:46:29,618] A new study created in RDB with name: PADel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: PADel\n",
      "A new study created in RDB with name: PADel\n",
      "Convs output size: 2\n",
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1386it [00:58, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.1324329789321179\n",
      "Last loss: 0.12762539469679385\n",
      "Validation epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "347it [00:13, 24.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.11542691591824177\n",
      "---\n",
      "Training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "158it [00:07, 20.87it/s]\n",
      "[W 2025-05-25 23:47:50,074] Trial 0 failed with parameters: {'activation': 'ReLU', 'optimizer': 'Adam', 'learning_rate': 0.00047446153692471234, 'momentum': 0.9, 'init weight': False} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24022/1031468632.py\", line 28, in objective\n",
      "    one_epoch_train(model, train_loader, optimizer, loss_function, verbose=False)\n",
      "  File \"/tmp/ipykernel_24022/1592106897.py\", line 4, in one_epoch_train\n",
      "    for i, data in tqdm(enumerate(train_loader)):\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 525, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 962, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 failed with parameters: {'activation': 'ReLU', 'optimizer': 'Adam', 'learning_rate': 0.00047446153692471234, 'momentum': 0.9, 'init weight': False} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24022/1031468632.py\", line 28, in objective\n",
      "    one_epoch_train(model, train_loader, optimizer, loss_function, verbose=False)\n",
      "  File \"/tmp/ipykernel_24022/1592106897.py\", line 4, in one_epoch_train\n",
      "    for i, data in tqdm(enumerate(train_loader)):\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 525, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 962, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Trial 0 failed with parameters: {'activation': 'ReLU', 'optimizer': 'Adam', 'learning_rate': 0.00047446153692471234, 'momentum': 0.9, 'init weight': False} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24022/1031468632.py\", line 28, in objective\n",
      "    one_epoch_train(model, train_loader, optimizer, loss_function, verbose=False)\n",
      "  File \"/tmp/ipykernel_24022/1592106897.py\", line 4, in one_epoch_train\n",
      "    for i, data in tqdm(enumerate(train_loader)):\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 525, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 962, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-25 23:47:50,084] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m storage_name = \u001b[33m\"\u001b[39m\u001b[33msqlite:///\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.db\u001b[39m\u001b[33m\"\u001b[39m.format(study_name)\n\u001b[32m      4\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m, study_name=study_name, storage=storage_name, load_if_exists=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m study.optimize(objective, n_trials=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     _optimize(\n\u001b[32m    476\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    477\u001b[39m         func=func,\n\u001b[32m    478\u001b[39m         n_trials=n_trials,\n\u001b[32m    479\u001b[39m         timeout=timeout,\n\u001b[32m    480\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    481\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    482\u001b[39m         callbacks=callbacks,\n\u001b[32m    483\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    484\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    485\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         _optimize_sequential(\n\u001b[32m     64\u001b[39m             study,\n\u001b[32m     65\u001b[39m             func,\n\u001b[32m     66\u001b[39m             n_trials,\n\u001b[32m     67\u001b[39m             timeout,\n\u001b[32m     68\u001b[39m             catch,\n\u001b[32m     69\u001b[39m             callbacks,\n\u001b[32m     70\u001b[39m             gc_after_trial,\n\u001b[32m     71\u001b[39m             reseed_sampler_rng=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     72\u001b[39m             time_start=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     73\u001b[39m             progress_bar=progress_bar,\n\u001b[32m     74\u001b[39m         )\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = _run_trial(study, func, catch)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = func(trial)\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTraining epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     one_epoch_train(model, train_loader, optimizer, loss_function, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mValidation epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m     epoch_last_val_loss = one_epoch_eval(model, test_loader, loss_function, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mone_epoch_train\u001b[39m\u001b[34m(model, train_loader, optimizer, loss_function, verbose)\u001b[39m\n\u001b[32m      2\u001b[39m running_loss = \u001b[32m0\u001b[39m\n\u001b[32m      3\u001b[39m model.train()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader)):\n\u001b[32m      5\u001b[39m     inputs,labels, _ = data\n\u001b[32m      6\u001b[39m     inputs,labels = inputs.to(device), labels.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m   1182\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[32m   1183\u001b[39m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1448\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m idx, data = \u001b[38;5;28mself\u001b[39m._get_data()\n\u001b[32m   1449\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1412\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1409\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m         success, data = \u001b[38;5;28mself\u001b[39m._try_get_data()\n\u001b[32m   1413\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1414\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1243\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1231\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1241\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m         data = \u001b[38;5;28mself\u001b[39m._data_queue.get(timeout=timeout)\n\u001b[32m   1244\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1247\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/queues.py:122\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    120\u001b[39m         \u001b[38;5;28mself\u001b[39m._rlock.release()\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:541\u001b[39m, in \u001b[36mrebuild_storage_fd\u001b[39m\u001b[34m(cls, df, size)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     fd = df.detach()\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    543\u001b[39m         storage = storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py:57\u001b[39m, in \u001b[36mDupFd.detach\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _resource_sharer.get_connection(\u001b[38;5;28mself\u001b[39m._id) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction.recv_handle(conn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/resource_sharer.py:86\u001b[39m, in \u001b[36m_ResourceSharer.get_connection\u001b[39m\u001b[34m(ident)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m     85\u001b[39m address, key = ident\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m c = Client(address, authkey=process.current_process().authkey)\n\u001b[32m     87\u001b[39m c.send((key, os.getpid()))\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:525\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(address, family, authkey)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mauthkey should be a byte string\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     answer_challenge(c, authkey)\n\u001b[32m    526\u001b[39m     deliver_challenge(c, authkey)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:962\u001b[39m, in \u001b[36manswer_challenge\u001b[39m\u001b[34m(connection, authkey)\u001b[39m\n\u001b[32m    960\u001b[39m digest = _create_response(authkey, message)\n\u001b[32m    961\u001b[39m connection.send_bytes(digest)\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m response = connection.recv_bytes(\u001b[32m256\u001b[39m)        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response != _WELCOME:\n\u001b[32m    964\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[33m'\u001b[39m\u001b[33mdigest sent was rejected\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:216\u001b[39m, in \u001b[36m_ConnectionBase.recv_bytes\u001b[39m\u001b[34m(self, maxlength)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength < \u001b[32m0\u001b[39m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mnegative maxlength\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m buf = \u001b[38;5;28mself\u001b[39m._recv_bytes(maxlength)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m._bad_message_length()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28mself\u001b[39m._recv(\u001b[32m4\u001b[39m)\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/jungle/lib/python3.12/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = read(handle, remaining)\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"PADel\"\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb27ee",
   "metadata": {},
   "source": [
    "device = 'cuda'\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "model = pd.read_pickle('/home/teobaldo/Uni/LCP-B/proj/GalaxyClassifier/artifacts/0ddf5239-9466-41c5-8aa7-7f222cf815e5')\n",
    "DS = GalaxyJungle('../data/test/test_solutions_rev1.csv', '../data/test/', transfs)\n",
    "train_loader = DataLoader(DS, batch_size=1, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "stuff = next(iter(train_loader))\n",
    "print('TRUE LABEL\\n')\n",
    "print(stuff[1])\n",
    "model.eval()\n",
    "out = model(stuff[0].to(device))\n",
    "print('PREDICT\\n')\n",
    "print(out)\n",
    "\n",
    "print('TRUE LABEL - PREDICT\\n')\n",
    "print(stuff[1].to(device) - out)\n",
    "plt.imshow(stuff[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017501d",
   "metadata": {},
   "source": [
    "model = pd.read_pickle('./artifacts/fbd42892-4aa7-409e-84e3-17fafae221cc')\n",
    "\n",
    "\n",
    "# print(model.loss_dict)\n",
    "print('?', model.loss_dict['epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009c8fe",
   "metadata": {},
   "source": [
    "lossd = pd.read_pickle('/home/teobaldo/Uni/LCP-B/proj/GalaxyClassifier/artifacts/ec3820ea-6658-47f3-8139-94ad4a8883c5').loss_dict\n",
    "lossd.keys()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "ax.grid(alpha=0.3)\n",
    "ax.plot(range(len(lossd['batch'])), lossd['batch'], label='Training')\n",
    "ax.plot(range(len(lossd['vbatch'])), lossd['vbatch'], label='Validation')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jungle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
