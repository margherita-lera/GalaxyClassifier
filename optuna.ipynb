{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c831bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teobaldo/miniconda3/envs/jungle/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#import torch.utils.data\n",
    "#from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f15060",
   "metadata": {},
   "source": [
    "### Define Dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cac3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyJungle(Dataset):\n",
    "    \n",
    "    #the init function initializes the directory containing the image,\n",
    "    #the annotations file,\n",
    "    #and both transforms\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, is_rgb=False):\n",
    "        self.rgb = is_rgb\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    #returns number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return (self.img_labels).shape[0]\n",
    "\n",
    "    #loads a sample from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])) + '.jpg'\n",
    "        #retrieves the image\n",
    "        image = Image.open(img_path)\n",
    "        if not self.rgb: image = image.convert('L')\n",
    "        #retrieves corresponding label\n",
    "        label = self.img_labels.iloc[idx, 1:]\n",
    "        #if possible, transform the image and the label into a tensor.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, self.img_labels.iloc[idx, 0]\n",
    "    \n",
    "\n",
    "transfs = transforms.Compose([\n",
    "    transforms.ToTensor(), # Riscala le immagini tra 0 e 1\n",
    "    # sarebbe interessante implementare un random crop prima del center crop per decentrare un poco le immagini????\n",
    "    transforms.RandomHorizontalFlip(), # horizontal flip\n",
    "    transforms.RandomVerticalFlip(), # vertical flip\n",
    "    transforms.CenterCrop(324)          #CROP\n",
    "    ]) #transforms.compose per fare una pipe di transformazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0592f53",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d162ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyNet(nn.Module):\n",
    "    def __init__(self, n_conv_layers, num_filters, num_neurons1, num_neurons2, activation, is_rgb=False, verbose=False):\n",
    "        super().__init__()\n",
    "        self.rgb = 3 if is_rgb else 1\n",
    "        self.input_size = 324\n",
    "        self.num_labels = 37\n",
    "        self.loss_dict = { 'batch' : [], 'epoch' : [], 'vbatch' : [], 'vepoch' : []}\n",
    "        self.activation= activation\n",
    "\n",
    "\n",
    "        stride = 2\n",
    "        kernel_size = 3\n",
    "        kernel_size_pool = 2\n",
    "        \n",
    "        ## convolutional layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(self.rgb, num_filters[0], kernel_size=kernel_size, stride=stride),\n",
    "            nn.BatchNorm2d(num_filters[0])\n",
    "            ])\n",
    "        output_size = (self.input_size - kernel_size + stride) // (stride*kernel_size_pool)\n",
    "\n",
    "        if verbose: print('output size after first conv layer: ', output_size)\n",
    "\n",
    "        for i in range(1,n_conv_layers):\n",
    "            self.convs.append(nn.Conv2d(num_filters[i-1], num_filters[i], kernel_size=kernel_size, stride=stride)) # num filters are the number of channel the conv layer outputs.\n",
    "            self.convs.append(nn.BatchNorm2d(num_filters[i]))\n",
    "            output_size = (output_size - kernel_size + stride) // (stride*kernel_size_pool) #padding 0, dilation = 1\n",
    "            if verbose: \n",
    "                if i != n_conv_layers - 1: print('output size after conv layer {}: '.format(i), output_size)\n",
    "                else: \n",
    "                    print('output size of the last conv layer: ', output_size)\n",
    "                    print('len self convs: ',len(self.convs))\n",
    "                    \n",
    "        self.pool = nn.MaxPool2d(kernel_size=kernel_size_pool)\n",
    "        #self.convs.append(nn.dropout(p= value)) ## to be added in the future to test claims of BatchnOrm paper\n",
    "        \n",
    "        self.out_feature = num_filters[-1] *output_size * output_size # output size of the last conv layer, should be 38\n",
    "        self.fc1 = nn.Linear(self.out_feature, num_neurons1) # fully connected layer\n",
    "        # dropout here if you want\n",
    "        self.fc2 = nn.Linear(num_neurons1, num_neurons2)\n",
    "        #dropout here if u want\n",
    "        self.fc3 = nn.Linear(num_neurons2, self.num_labels)\n",
    "\n",
    "    def init_weights(self,  mode, n_conv_layers):\n",
    "        if mode == 'relu': # perchè kaiming normal e non uniform??1\n",
    "            for i in range(0, n_conv_layers*2, 2):\n",
    "                nn.init.kaiming_normal_(self.convs[i].weight, nonlinearity=mode)\n",
    "                if self.convs[i].bias is not None:\n",
    "                    nn.init.constant_(self.convs[i].bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=mode)\n",
    "            if self.fc1.bias is not None:\n",
    "                nn.init.constant_(self.fc1.bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc2.weight, nonlinearity=mode)\n",
    "            if self.fc2.bias is not None:\n",
    "                nn.init.constant_(self.fc2.bias,0)\n",
    "        elif mode == 'leaky_relu':\n",
    "            for i in range(0, n_conv_layers*2, 2):\n",
    "                nn.init.kaiming_normal_(self.convs[i].weight, a = 0.01, nonlinearity=mode)\n",
    "                if self.convs[i].bias is not None:\n",
    "                    nn.init.constant_(self.convs[i].bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=mode)\n",
    "            if self.fc1.bias is not None:\n",
    "                nn.init.constant_(self.fc1.bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc2.weight, nonlinearity=mode)\n",
    "            if self.fc2.bias is not None:\n",
    "                nn.init.constant_(self.fc2.bias,0) \n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        if self.fc3.bias is not None:\n",
    "            nn.init.constant_(self.fc3.bias,0)\n",
    "        return print('weights initialized with {}'.format(mode))        \n",
    "        \n",
    "\n",
    "    def forward(self,x):#, activation):\n",
    "        verbose=False\n",
    "        for i in range(0, len(self.convs),2):\n",
    "            x = self.convs[i](x)  # conv\n",
    "            x = self.activation(x)  # act\n",
    "            x = self.convs[i+1](x)  # batch norm\n",
    "            x = self.pool(x)  # pool\n",
    "            if verbose: print(x.shape)\n",
    "        x = torch.flatten(x,1) # flatten operation -> 1 dimensional\n",
    "        if verbose: print('last conv layer flattened',x.shape)\n",
    "        if verbose: print('out-feature: ',self.out_feature)\n",
    "        x = self.activation(self.fc1(x)) # apply relu al'output dei fully connected\n",
    "        if verbose: print(x.shape)\n",
    "        x = self.activation(self.fc2(x)) # idem sopra\n",
    "        if verbose: print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "        # x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def log_the_loss(self, item,epoch=False): # per avere una history della loss???\n",
    "        verbose=False\n",
    "        train = self.__getstate__()['training']\n",
    "        if verbose: print(train)\n",
    "        if epoch and train:\n",
    "            self.loss_dict['epoch'].append(item) ### get state of the model so you can ditch the validation parameter\n",
    "        elif not epoch and train:\n",
    "            self.loss_dict['batch'].append(item)\n",
    "        elif not train and epoch:\n",
    "            self.loss_dict['vepoch'].append(item)\n",
    "        elif not train and not epoch:\n",
    "            self.loss_dict['vbatch'].append(item)\n",
    "        return item\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d78d12",
   "metadata": {},
   "source": [
    "## Initialization of DS and NN\n",
    "Example of Galaxy Net. We use it to implement the training and validation below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06e03fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = False\n",
    "\n",
    "DS = GalaxyJungle('../data/training/training_solutions_rev1.csv', '../data/training/', transfs, is_rgb=rgb)\n",
    "training, test, true_test = random_split(DS, [.65, .2, .15])\n",
    "train_loader = DataLoader(training, batch_size=(batch_size_train := 512), shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test, batch_size=(batch_size_test := 512), shuffle=False, num_workers=8)\n",
    "\n",
    "#n_conv_layers, num_filters,num_neurons1, num_neurons2):\n",
    "gnet = GalaxyNet(2,[3,6],50, 45, nn.ReLU(), is_rgb=rgb).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efe364",
   "metadata": {},
   "source": [
    "img, lab, indx = DS.__getitem__(0)\n",
    "#print(lab)\n",
    "#print(img)         #3D TENSOR    \n",
    "if DS.rgb:\n",
    "    fig, ax = plt.subplots(1,3, figsize=(24,7))\n",
    "    color = ['Reds', 'Greens', 'Blues']\n",
    "    for i,j in enumerate(img):\n",
    "        ax[i].imshow(j, cmap=color[i])\n",
    "else:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(24,7))\n",
    "    ax.imshow(img[0], cmap='magma')\n",
    "#print(img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357637a",
   "metadata": {},
   "source": [
    "## TRAINING + VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fad1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(gnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8aedbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(verbose=False):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    gnet.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs,labels, _ = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = gnet(inputs) #, activation=F.relu)\n",
    "        loss=loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # fa update del parameter\n",
    "        RMSEloss = np.sqrt(loss.item())\n",
    "        running_loss += RMSEloss\n",
    "        if verbose and i%10 ==0: print(f'Batch {i+1}/{len(train_loader)} - Loss: {RMSEloss:.3f}')\n",
    "\n",
    "        gnet.log_the_loss(RMSEloss, epoch=False)\n",
    "    epochmean_loss = running_loss / len(train_loader)\n",
    "    print(f'\\nLoss: {epochmean_loss:.3f}')\n",
    "    gnet.log_the_loss(epochmean_loss, epoch=True)\n",
    "    last_loss = RMSEloss\n",
    "    print(f\"Last loss: {last_loss:.3f}\")\n",
    "    return epochmean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c61382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_eval(verbose=False):\n",
    "    gnet.eval()\n",
    "    running_validation_loss = 0.\n",
    "   \n",
    "    with torch.no_grad(): # deactivates gradient evaluation\n",
    "        for i, vdata in enumerate(test_loader):\n",
    "            inputs,labels, _ = vdata\n",
    "            inputs,labels= inputs.to(device), labels.to(device)\n",
    "            outputs = gnet(inputs)#, activation=F.relu)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            RMSEloss = np.sqrt(loss.item())\n",
    "            running_validation_loss +=RMSEloss\n",
    "            gnet.log_the_loss(RMSEloss,epoch=False)\n",
    "    mean_vloss=gnet.log_the_loss(running_validation_loss/len(test_loader),epoch=True)\n",
    "    if verbose: print(f\"Validation Loss: {mean_vloss:.3f}\\n---\")\n",
    "    return mean_vloss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "Batch 1/79 - Loss: 0.295\n",
      "Batch 11/79 - Loss: 0.283\n",
      "Batch 21/79 - Loss: 0.270\n",
      "Batch 31/79 - Loss: 0.260\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTraining epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     epoch_last_loss = one_epoch_train(verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEnd of epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEvaluation epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mone_epoch_train\u001b[39m\u001b[34m(verbose)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m      6\u001b[39m     inputs,labels, _ = data\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     inputs,labels = inputs.to(device), labels.to(device)\n\u001b[32m      8\u001b[39m     optimizer.zero_grad()\n\u001b[32m      9\u001b[39m     outputs = gnet(inputs) \u001b[38;5;66;03m#, activation=F.relu)\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0,1):\n",
    "    print(f'Training epoch {epoch}')\n",
    "    epoch_last_loss = one_epoch_train(verbose=FalseTrue)\n",
    "    print(f'End of epoch {epoch} \\n---')\n",
    "    print(f'Evaluation epoch {epoch}')\n",
    "    epoch_vloss = one_epoch_eval(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590107b",
   "metadata": {},
   "source": [
    "## OPTUNA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a8f516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    num_conv_layers = trial.suggest_int(\"num_conv_layers\", 2, 5, 1)\n",
    "    # qui tuniamo il numero di filtri, per layer più profondi ci vogliono più filtri \n",
    "    # (64-28 è consigliato per pattern astratti e combinazioni, mentre fino a 32 per dettagli locali) \n",
    "    # quindi proviamo (VGG usa fino a 512 per esempio).\n",
    "    num_filters = [int(trial.suggest_discrete_uniform(\"num_filters_\"+str(i), 16, 128, 16)) for i in range(num_conv_layers)]\n",
    "    # abbiamo numneurons1 e numn neurons2,se mettiamo un grid sampler o un random sampler \n",
    "    # con num_neurons e basta penso che lui provi diverse combinazioni\n",
    "    num_neurons = trial.suggest_int(\"num_neurons\",10,200,10) \n",
    "    # abbiamo chiamato mode l'activation function nell'initialization dei pesi o la chiamiamo activation\n",
    "    # così optuna poi inizializza in base a quello.\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\"])\n",
    "    \n",
    "    #da capire come inserire.\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"AdamW\"]) #AdamW è suggerito per CNN.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True) #log true cerca i valori in scala logaritmica\n",
    "\n",
    "    # batch size da tunare?\n",
    "    # batch_size = trial.suggest_int(\"batch_size\", 16, 128, 16)\n",
    "\n",
    "    #(self, n_conv_layers, num_filters,num_neurons1, num_neurons2, activation):\n",
    "    model = GalaxyNet(trial, num_conv_layers, num_filters, num_neurons, num_neurons, activation).to(device)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca7524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
